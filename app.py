# ---------------------------------------------------------------------------
# Streamlit Web App: Meal Detection AI (Session State ì ìš© ë²„ì „)
# ---------------------------------------------------------------------------
import streamlit as st
import pandas as pd
import numpy as np
import tensorflow as tf
import matplotlib.pyplot as plt
import joblib
import os
import glob
from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score, roc_auc_score

# --- 1. í˜ì´ì§€ ì„¤ì • ---
st.set_page_config(page_title="Meal Detection AI", layout="wide")

st.title("ğŸ½ï¸ Meal Detection AI Analysis")
st.markdown("""
ì´ ì•±ì€ í•™ìŠµëœ AI ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ìƒì²´ ë°ì´í„°ì—ì„œ **ì‹ì‚¬ êµ¬ê°„(Meal Intervals)**ì„ ìë™ìœ¼ë¡œ íƒì§€í•©ë‹ˆë‹¤.
ì—…ë¡œë“œëœ íŒŒì¼(`csv`)ì„ ë¶„ì„í•˜ì—¬ ì‹ì‚¬ í™•ë¥ , ì˜ˆìƒ êµ¬ê°„, ê·¸ë¦¬ê³  ìƒì„¸ ë¦¬í¬íŠ¸ë¥¼ ì œê³µí•©ë‹ˆë‹¤.
""")

# --- [ì¤‘ìš”] í•™ìŠµ íŒŒë¼ë¯¸í„° ê³ ì • (JSON íŒŒì¼ ëŒ€ì²´) ---
FIXED_CONFIG = {
    'eval_window_size': 12,  # 60ë¶„
    'sub_window_size': 6,    # 30ë¶„
    'baseline_points': 4,    # 20ë¶„
    'stride': 1              # 5ë¶„
}

# --- 2. íŒŒì¼ ìë™ íƒìƒ‰ í•¨ìˆ˜ ---
def find_latest_file(pattern, description):
    files = glob.glob(pattern)
    if not files:
        st.error(f"âŒ {description} íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. (íŒ¨í„´: `{pattern}`)")
        return None
    return max(files, key=os.path.getmtime)

# --- 3. ë¦¬ì†ŒìŠ¤ ë¡œë“œ ---
@st.cache_resource
def load_resources():
    model_file = find_latest_file("trained_model_*.h5", "AI ëª¨ë¸")
    if model_file is None: return None, None, None
    
    try:
        model = tf.keras.models.load_model(model_file)
    except Exception as e:
        st.error(f"ëª¨ë¸ ë¡œë“œ ì˜¤ë¥˜ ({model_file}): {e}")
        return None, None, None

    scaler_file = find_latest_file("scaler_*.pkl", "ìŠ¤ì¼€ì¼ëŸ¬")
    if scaler_file is None: return None, None, None
        
    try:
        scaler = joblib.load(scaler_file)
    except Exception as e:
        st.error(f"ìŠ¤ì¼€ì¼ëŸ¬ ë¡œë“œ ì˜¤ë¥˜ ({scaler_file}): {e}")
        return None, None, None

    filenames = {
        "model": os.path.basename(model_file),
        "scaler": os.path.basename(scaler_file)
    }

    return model, scaler, filenames

resources = load_resources()
if resources is None or resources[0] is None:
    st.warning("í•„ìš”í•œ íŒŒì¼(.h5, .pkl)ì´ GitHub ì €ì¥ì†Œì— ìˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.")
    st.stop()

model, scaler_global, filenames = resources

# --- 4. ì‚¬ì´ë“œë°” ì„¤ì • ---
st.sidebar.header("âš™ï¸ ë¶„ì„ ì„¤ì •")
st.sidebar.success(f"âœ… ëª¨ë¸ ë¡œë“œ: `{filenames['model']}`")
st.sidebar.info(f"""
**ğŸ”’ ì ìš©ëœ í•™ìŠµ íŒŒë¼ë¯¸í„°**
- í‰ê°€ êµ¬ê°„: {FIXED_CONFIG['eval_window_size']*5}ë¶„
- ì„œë¸Œ ìœˆë„ìš°: {FIXED_CONFIG['sub_window_size']*5}ë¶„
- ê¸°ì¤€ ì²´ì˜¨ êµ¬ê°„: {FIXED_CONFIG['baseline_points']*5}ë¶„
- Stride: {FIXED_CONFIG['stride']*5}ë¶„
""")

st.sidebar.markdown("---")
st.sidebar.subheader("ğŸšï¸ ë¯¼ê°ë„ ì¡°ì ˆ")

temp_change_limit = st.sidebar.slider("ê¸‰ë³€ ì²´ì˜¨ ê¸°ì¤€ (Â°C)", 1.0, 2.0, 1.2, 0.1)
prob_threshold = st.sidebar.slider("ì„œë¸Œìœˆë„ìš° íŒì • ê¸°ì¤€ (Prob)", 0.1, 0.9, 0.5, 0.05)
# [ìˆ˜ì •] ìœˆë„ìš° ì‹ì‚¬ ë¹„ìœ¨ ê¸°ë³¸ê°’ 0.3 -> 0.2 ë³€ê²½
window_meal_threshold = st.sidebar.slider("ìœˆë„ìš° ì‹ì‚¬ ë¹„ìœ¨ (Ratio)", 0.1, 0.9, 0.2, 0.05)
gt_threshold = st.sidebar.slider("ì •ë‹µ ë¼ë²¨ ê¸°ì¤€ (GT)", 0.1, 0.9, 0.5, 0.05)

# --- 5. í—¬í¼ í•¨ìˆ˜ ---
def minutes_to_time(minutes):
    hours = int(minutes // 60) % 24 
    mins = int(minutes % 60)
    return f"{hours:02d}:{mins:02d}"

def handle_missing_times(df):
    if 'Time(min)' not in df.columns and '24h_time' in df.columns:
        try:
            time_parts = df['24h_time'].str.split(':', expand=True).astype(int)
            df['Time(min)'] = time_parts[0] * 60 + time_parts[1]
        except: return None, False
    elif 'Time(min)' not in df.columns: return None, False

    all_subjects_filled_dfs = []
    for subject_id, group in df.groupby('Subject_ID'):
        group = group.sort_values(by='Time(min)').drop_duplicates(subset=['Time(min)'])
        min_time, max_time = group['Time(min)'].min(), group['Time(min)'].max()
        master_df = pd.DataFrame(index=pd.RangeIndex(start=min_time, stop=max_time + 5, step=5, name='Time(min)'))
        group = group.set_index('Time(min)')
        merged = master_df.join(group, how='left')
        merged['is_interpolated'] = pd.isna(merged['Subject_ID']).astype(int)
        merged['Subject_ID'] = subject_id
        merged['Label_EN'] = merged['Label_EN'].fillna('Not-Meal (Filled)')
        if 'BodyTemp(Â°C)' in merged.columns: merged.rename(columns={'BodyTemp(Â°C)': 'BodyTemp'}, inplace=True)
        merged['BodyTemp'] = merged['BodyTemp'].interpolate(method='linear', limit_direction='both').ffill().bfill()
        for col in ['Age', 'Sex', 'Weight(kg)', 'Menstrual']:
            if col in merged.columns: merged[col] = merged[col].ffill().bfill()
        all_subjects_filled_dfs.append(merged.reset_index())
    return pd.concat(all_subjects_filled_dfs, ignore_index=True), True

def create_sequences_for_test(df, target, temp_change_limit, threshold_ratio_gt):
    X, y, times, subjects, is_interp, is_arti = [], [], [], [], [], []
    eval_win, stride, base_pts, sub_win = FIXED_CONFIG['eval_window_size'], FIXED_CONFIG['stride'], FIXED_CONFIG['baseline_points'], FIXED_CONFIG['sub_window_size']
    
    if 'BodyTemp(Â°C)' in df.columns: df.rename(columns={'BodyTemp(Â°C)': 'BodyTemp'}, inplace=True)
    df = df.sort_values(['Subject_ID', 'Time(min)'])
    
    unique_subs = df['Subject_ID'].unique()
    prog_bar = st.progress(0)
    status_text = st.empty()
    
    for idx, (sid, group) in enumerate(df.groupby('Subject_ID')):
        prog_bar.progress((idx + 1) / len(unique_subs))
        status_text.text(f"Processing Subject ID: {sid} ({idx+1}/{len(unique_subs)})")
        group = group.reset_index(drop=True)
        end_idx = len(group) - base_pts - eval_win + 1
        if end_idx <= 0: continue

        for i in range(0, end_idx, stride):
            base_data = group.iloc[i : i + base_pts]
            base_avg = base_data['BodyTemp'].mean()
            is_base_interp = (base_data['is_interpolated'] == 1).any()
            eval_data = group.iloc[i + base_pts : i + base_pts + eval_win]
            
            diffs = eval_data['BodyTemp'].values - base_avg
            is_artifact = np.any(np.abs(diffs) >= temp_change_limit)
            sub_diffs_list = []
            label_gt = 1 if (eval_data[target] == 1).mean() >= threshold_ratio_gt else 0
            is_eval_interp = (eval_data['is_interpolated'] == 1).any() or is_base_interp

            if not is_artifact:
                for j in range(0, eval_win - sub_win + 1, 1): 
                    sub_data = eval_data.iloc[j : j + sub_win]
                    feat = sub_data['BodyTemp'].values - base_avg
                    sub_diffs_list.append(feat.reshape(sub_win, 1))
            if is_artifact: X.append(np.zeros((0, sub_win, 1)))
            else: X.append(np.array(sub_diffs_list))
            y.append(label_gt); times.append(group['Time(min)'].iloc[i + base_pts + eval_win - 1])
            subjects.append(sid); is_interp.append(is_eval_interp); is_arti.append(is_artifact)
            
    prog_bar.empty()
    status_text.empty()
    return X, np.array(y), np.array(times), np.array(subjects), np.array(is_interp), np.array(is_arti), True

def get_interval_string(end_times, window_size_min):
    if len(end_times) == 0: return "ì—†ìŒ"
    intervals = []
    offset = (window_size_min - 30) / 2
    for t in end_times:
        start = max(0, t - window_size_min)
        intervals.append([start + offset, start + offset + 30])
    intervals.sort(key=lambda x: x[0])
    merged = []
    if intervals:
        merged.append(intervals[0])
        for i in range(1, len(intervals)):
            if intervals[i][0] <= merged[-1][1] + 30: merged[-1][1] = max(merged[-1][1], intervals[i][1])
            else: merged.append(intervals[i])
    return ", ".join([f"{minutes_to_time(s)} ~ {minutes_to_time(e)}" for s, e in merged])

# --- 6. ë¶„ì„ íŒŒì´í”„ë¼ì¸ (Heavy Computation) ---
def run_analysis_pipeline(df_test, params):
    # ì „ì²˜ë¦¬
    with st.spinner("1/3 ë°ì´í„° ì „ì²˜ë¦¬ ì¤‘..."):
        df_processed, success = handle_missing_times(df_test)
        if not success: return None

    target = 'Label_EN'
    if target not in df_processed.columns: df_processed[target] = 0
    df_processed[target] = df_processed[target].apply(lambda x: 1 if str(x).lower() == 'meal' else 0)

    # ì‹œí€€ìŠ¤ ìƒì„±
    with st.spinner("2/3 ì‹œí€€ìŠ¤ ìƒì„± ì¤‘..."):
        X_list, y, ts, sids, is_int, is_art, ok = create_sequences_for_test(
            df_processed, target, params['temp_change_limit'], params['gt_threshold']
        )
    if not ok or len(X_list) == 0: return None

    # ì˜ˆì¸¡ (ê°€ì¥ ì˜¤ë˜ ê±¸ë¦¼)
    with st.spinner("3/3 AI ëª¨ë¸ ë¶„ì„ ì¤‘..."):
        preds, ratios = [], []
        # ë°°ì¹˜ ì˜ˆì¸¡ì„ ìœ„í•´ ë°ì´í„°ë¥¼ í‰íƒ„í™”í•˜ë©´ ì¢‹ê² ì§€ë§Œ, ë¡œì§ ìœ ì§€ë¥¼ ìœ„í•´ ë£¨í”„ ì‚¬ìš©
        # (Streamlitì—ì„œëŠ” ì§„í–‰ë¥  ë³´ì—¬ì£¼ëŠ”ê²Œ ë” ë‚˜ì„ ìˆ˜ ìˆìŒ)
        prog_bar = st.progress(0)
        total = len(X_list)
        
        for i, x in enumerate(X_list):
            if i % 100 == 0: prog_bar.progress((i+1)/total)
            
            if is_art[i] or len(x) == 0:
                preds.append(2); ratios.append(0.0)
                continue
            
            N, T, F = x.shape
            x_scaled = scaler_global.transform(x.reshape(-1, F)).reshape(N, T, F)
            probs = model.predict(x_scaled, verbose=0).flatten()
            
            r = np.mean((probs >= params['prob_threshold']).astype(int))
            ratios.append(r)
            preds.append(1 if r >= params['window_meal_threshold'] else 0)
        
        prog_bar.empty()

    y_pred = np.array(preds)
    y_pred[is_int] = 2
    y_ratios = np.array(ratios)

    # ê²°ê³¼ íŒ¨í‚¤ì§•
    return {
        'df_processed': df_processed,
        'y_true': y,
        'y_pred': y_pred,
        'y_ratios': y_ratios,
        'times': ts,
        'subjects': sids,
        'params': params
    }

# --- 7. ê²°ê³¼ ì‹œê°í™” ë° UI ---
uploaded_file = st.file_uploader("ğŸ“‚ í…ŒìŠ¤íŠ¸ ë°ì´í„° íŒŒì¼ ì—…ë¡œë“œ (CSV)", type=['csv'])

# ë²„íŠ¼ í´ë¦­ ì‹œ: ë¶„ì„ ì‹¤í–‰ ë° ê²°ê³¼ ì €ì¥
if uploaded_file is not None:
    if st.button("ğŸš€ ë¶„ì„ ì‹œì‘ (Run Analysis)"):
        params = {
            'temp_change_limit': temp_change_limit,
            'prob_threshold': prob_threshold,
            'window_meal_threshold': window_meal_threshold,
            'gt_threshold': gt_threshold
        }
        
        df_test = pd.read_csv(uploaded_file)
        results = run_analysis_pipeline(df_test, params)
        
        if results:
            st.session_state['analysis_results'] = results
            st.success("ë¶„ì„ ì™„ë£Œ! ì•„ë˜ì—ì„œ ê²°ê³¼ë¥¼ í™•ì¸í•˜ì„¸ìš”.")
        else:
            st.error("ë¶„ì„ ì‹¤íŒ¨: ìœ íš¨í•œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

# ì €ì¥ëœ ê²°ê³¼ê°€ ìˆìœ¼ë©´ í•­ìƒ í‘œì‹œ (ë²„íŠ¼ ì•ˆ ëˆŒëŸ¬ë„ ìœ ì§€ë¨)
if 'analysis_results' in st.session_state:
    res = st.session_state['analysis_results']
    params = res['params'] # ë¶„ì„ ë‹¹ì‹œì˜ íŒŒë¼ë¯¸í„° ì‚¬ìš©
    
    st.divider()
    st.subheader("ğŸ“Š ë¶„ì„ ê²°ê³¼")
    
    # ì „ì²´ ì„±ëŠ¥ ì§€í‘œ
    valid_mask = (res['y_pred'] != 2)
    if np.sum(valid_mask) > 0:
        y_valid = res['y_true'][valid_mask]
        p_valid = res['y_pred'][valid_mask]
        
        acc = accuracy_score(y_valid, p_valid)
        f1 = f1_score(y_valid, p_valid, average='weighted', zero_division=0)
        try: auc = roc_auc_score(y_valid, res['y_ratios'][valid_mask])
        except: auc = 0.0
        
        col1, col2, col3 = st.columns(3)
        col1.metric("ì •í™•ë„ (Accuracy)", f"{acc*100:.2f}%")
        col2.metric("F1 Score", f"{f1:.2f}")
        col3.metric("AUC", f"{auc:.2f}")
        
        with st.expander("ìƒì„¸ ì˜¤ì°¨ í–‰ë ¬ ë³´ê¸°"):
            cm = confusion_matrix(y_valid, p_valid, normalize='true', labels=[0, 1])
            st.dataframe(pd.DataFrame(cm*100, index=['Actual 0', 'Actual 1'], columns=['Pred 0', 'Pred 1']).style.format("{:.1f}%"))
    
    # ê°œë³„ ëŒ€ìƒì ë¶„ì„ (ì—¬ê¸°ì„œ ëŒ€ìƒìë¥¼ ë°”ê¿”ë„ ë¶„ì„ ì¬ì‹¤í–‰ ì•ˆ ë¨!)
    st.divider()
    st.subheader("ğŸ“ˆ ê°œë³„ ëŒ€ìƒì ìƒì„¸ ë¶„ì„")
    
    u_ids = np.unique(res['subjects'])
    selected_subject = st.selectbox("ëŒ€ìƒì ì„ íƒ:", u_ids)
    
    if selected_subject:
        mask = (res['subjects'] == selected_subject)
        sub_t = res['times'][mask]
        sub_r = res['y_ratios'][mask]
        sub_y = res['y_true'][mask]
        sub_p = res['y_pred'][mask]
        
        # ì‹œê°„ìˆœ ì •ë ¬
        sort_idx = np.argsort(sub_t)
        sub_t = sub_t[sort_idx]
        sub_r = sub_r[sort_idx]
        sub_y = sub_y[sort_idx]
        sub_p = sub_p[sort_idx]
        
        t_strs = [minutes_to_time(m) for m in sub_t]
        
        fig, ax = plt.subplots(figsize=(12, 4))
        ax.plot(t_strs, sub_r, label='Meal Ratio', color='royalblue')
        ax.axhline(y=params['window_meal_threshold'], color='red', linestyle='--', label='Threshold')
        
        ax.fill_between(t_strs, 0, 1, where=(sub_y==1), color='green', alpha=0.2, label='Actual Meal', transform=ax.get_xaxis_transform())
        ax.fill_between(t_strs, 0, 1, where=(sub_p==2), color='gray', alpha=0.5, label='Unknown', transform=ax.get_xaxis_transform(), step='post')
        
        ax.set_ylim(-0.05, 1.05)
        tick_idx = np.linspace(0, len(t_strs)-1, min(15, len(t_strs)), dtype=int)
        ax.set_xticks([t_strs[i] for i in tick_idx])
        plt.xticks(rotation=45)
        ax.legend(loc='upper left')
        ax.grid(True, alpha=0.5)
        st.pyplot(fig)
        
        # ì˜ˆì¸¡ êµ¬ê°„ í…ìŠ¤íŠ¸
        detected_times = sub_t[sub_p == 1]
        eval_win_min = FIXED_CONFIG['eval_window_size'] * 5
        st.write(f"ğŸ•’ **ì˜ˆì¸¡ ì‹ì‚¬ êµ¬ê°„:** {get_interval_string(detected_times, eval_win_min)}")
        
        # ì›ë³¸ ë°ì´í„° í™•ì¸
        with st.expander("ì›ë³¸ ì²´ì˜¨ ë°ì´í„° ë³´ê¸°"):
            raw_df = res['df_processed']
            sub_raw = raw_df[raw_df['Subject_ID'] == selected_subject].sort_values('Time(min)')
            sub_raw['Time_str'] = sub_raw['Time(min)'].apply(minutes_to_time)
            
            fig2, ax2 = plt.subplots(figsize=(12, 3))
            ax2.plot(sub_raw['Time_str'], sub_raw['BodyTemp'], color='orange', label='BodyTemp')
            ax2.set_xticks(sub_raw['Time_str'][::max(1, len(sub_raw)//15)])
            plt.xticks(rotation=45)
            ax2.grid(True, alpha=0.5)
            st.pyplot(fig2)